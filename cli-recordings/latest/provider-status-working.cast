{"version": 2, "width": 195, "height": 42, "timestamp": 1749525717, "env": {"SHELL": "/bin/zsh", "TERM": "xterm-256color"}}
[0.559649, "o", "\u001b[?25l"]
[0.560522, "o", "\u001b[1G\u001b[1G\u001b[36m‚†ã\u001b[39m üîç Checking AI provider status...\r\n[AIProviderFactory.createProvider] Provider creation started { providerName: \u001b[32m'openai'\u001b[39m, modelName: \u001b[32m'default'\u001b[39m }\r\n"]
[0.560629, "o", "[OpenAI.constructor] Function called { modelName: \u001b[32m'gpt-4o'\u001b[39m }\r\n"]
[0.560728, "o", "[OpenAI.constructor] Function result { modelName: \u001b[32m'gpt-4o'\u001b[39m, success: \u001b[33mtrue\u001b[39m }\r\n[AIProviderFactory.createProvider] Provider creation succeeded {\r\n  providerName: \u001b[32m'openai'\u001b[39m,\r\n  modelName: \u001b[32m'default'\u001b[39m,\r\n  providerType: \u001b[32m'OpenAI'\u001b[39m\r\n}\r\n"]
[0.560837, "o", "[OpenAI.generate] Generate text started {\r\n  provider: \u001b[32m'openai'\u001b[39m,\r\n  modelName: \u001b[32m'gpt-4o'\u001b[39m,\r\n  promptLength: \u001b[33m4\u001b[39m,\r\n  temperature: \u001b[33m0.7\u001b[39m,\r\n  maxTokens: \u001b[33m1\u001b[39m\r\n}\r\n"]
[0.640876, "o", "\u001b[1G"]
[0.640934, "o", "\u001b[0K\u001b[1A\u001b[0K\u001b[36m‚†ô\u001b[39m Testing openai..."]
[0.721281, "o", "\u001b[1G\u001b[0K"]
[0.721446, "o", "\u001b[36m‚†π\u001b[39m Testing openai..."]
[0.800662, "o", "\u001b[1G\u001b[0K"]
[0.800812, "o", "\u001b[36m‚†∏\u001b[39m Testing openai..."]
[0.881084, "o", "\u001b[1G\u001b[0K\u001b[36m‚†º\u001b[39m Testing openai..."]
[0.961241, "o", "\u001b[1G\u001b[0K"]
[0.961377, "o", "\u001b[36m‚†¥\u001b[39m Testing openai..."]
[1.041106, "o", "\u001b[1G\u001b[0K"]
[1.041251, "o", "\u001b[36m‚†¶\u001b[39m Testing openai..."]
[1.121428, "o", "\u001b[1G"]
[1.12162, "o", "\u001b[0K\u001b[36m‚†ß\u001b[39m Testing openai..."]
[1.201738, "o", "\u001b[1G\u001b[0K"]
[1.20188, "o", "\u001b[36m‚†á\u001b[39m Testing openai..."]
[1.282439, "o", "\u001b[1G\u001b[0K"]
[1.282595, "o", "\u001b[36m‚†è\u001b[39m Testing openai..."]
[1.363224, "o", "\u001b[1G\u001b[0K\u001b[36m‚†ã\u001b[39m Testing openai..."]
[1.366211, "o", "[OpenAI.generate] Generate text completed {\r\n  provider: \u001b[32m'openai'\u001b[39m,\r\n  modelName: \u001b[32m'gpt-4o'\u001b[39m,\r\n  usage: { promptTokens: \u001b[33m19\u001b[39m, completionTokens: \u001b[33m1\u001b[39m, totalTokens: \u001b[33m20\u001b[39m },\r\n  finishReason: \u001b[32m'length'\u001b[39m,\r\n  responseLength: \u001b[33m5\u001b[39m\r\n}\r\n"]
[1.366486, "o", "\u001b[1G\u001b[0K\u001b[?25h\u001b[32m‚úî\u001b[39m openai: \u001b[32m‚úÖ Working\u001b[39m (806ms)\r\n"]
[1.36677, "o", "[AIProviderFactory.createProvider] Provider creation started { providerName: \u001b[32m'bedrock'\u001b[39m, modelName: \u001b[32m'default'\u001b[39m }\r\n"]
[1.36699, "o", "[AmazonBedrock.constructor] Function called {\r\n  modelName: \u001b[32m'arn:aws:bedrock:us-east-2:225681119357:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0'\u001b[39m,\r\n  envBedrockModel: \u001b[32m'arn:aws:bedrock:us-east-2:225681119357:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0'\u001b[39m,\r\n  envBedrockModelId: \u001b[90mundefined\u001b[39m,\r\n  fallbackModel: \u001b[32m'arn:aws:bedrock:us-east-2:225681119357:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0'\u001b[39m\r\n}\r\n"]
[1.367111, "o", "[AmazonBedrock.constructor] AWS config validation {\r\n  hasAccessKeyId: \u001b[33mtrue\u001b[39m,\r\n  hasSecretAccessKey: \u001b[33mtrue\u001b[39m,\r\n  region: \u001b[32m'us-east-2'\u001b[39m,\r\n  accessKeyIdLength: \u001b[33m20\u001b[39m,\r\n  hasSessionToken: \u001b[33mtrue\u001b[39m\r\n}\r\n"]
[1.367195, "o", "[AmazonBedrock.constructor] Session token added { environment: \u001b[32m'dev'\u001b[39m }\r\n[AmazonBedrock.constructor] AWS config created { region: \u001b[32m'us-east-2'\u001b[39m, hasSessionToken: \u001b[33mtrue\u001b[39m }\r\n"]
[1.367264, "o", "[AmazonBedrock.constructor] Bedrock provider creating {\r\n  modelName: \u001b[32m'arn:aws:bedrock:us-east-2:225681119357:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0'\u001b[39m\r\n}\r\n"]
[1.367359, "o", "[AmazonBedrock.constructor] Bedrock provider initialized {\r\n  modelName: \u001b[32m'arn:aws:bedrock:us-east-2:225681119357:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0'\u001b[39m\r\n}\r\n[AmazonBedrock.constructor] Model instance creating {\r\n  modelName: \u001b[32m'arn:aws:bedrock:us-east-2:225681119357:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0'\u001b[39m\r\n}\r\n"]
[1.369514, "o", "[AmazonBedrock.constructor] Model instance created {\r\n  modelName: \u001b[32m'arn:aws:bedrock:us-east-2:225681119357:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0'\u001b[39m\r\n}\r\n[AmazonBedrock.constructor] Function result {\r\n  modelName: \u001b[32m'arn:aws:bedrock:us-east-2:225681119357:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0'\u001b[39m,\r\n  region: \u001b[32m'us-east-2'\u001b[39m,\r\n  hasSessionToken: \u001b[33mtrue\u001b[39m,\r\n  success: \u001b[33mtrue\u001b[39m\r\n}\r\n"]
[1.369912, "o", "[AmazonBedrock.constructor] Initialization completed {\r\n  modelName: \u001b[32m'arn:aws:bedrock:us-east-2:225681119357:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0'\u001b[39m,\r\n  region: \u001b[32m'us-east-2'\u001b[39m,\r\n  hasSessionToken: \u001b[33mtrue\u001b[39m\r\n}\r\n"]
[1.369935, "o", "[AIProviderFactory.createProvider] Provider creation succeeded {\r\n  providerName: \u001b[32m'bedrock'\u001b[39m,\r\n  modelName: \u001b[32m'default'\u001b[39m,\r\n  providerType: \u001b[32m'AmazonBedrock'\u001b[39m\r\n}\r\n"]
[1.371118, "o", "[AmazonBedrock.generate] Generate text started {\r\n  provider: \u001b[32m'bedrock'\u001b[39m,\r\n  modelName: \u001b[32m'arn:aws:bedrock:us-east-2:225681119357:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0'\u001b[39m,\r\n  region: \u001b[32m'us-east-2'\u001b[39m,\r\n  promptLength: \u001b[33m4\u001b[39m,\r\n  temperature: \u001b[33m0.7\u001b[39m,\r\n  maxTokens: \u001b[33m1\u001b[39m\r\n}\r\n"]
[2.162317, "o", "[AmazonBedrock.generate] Exception {\r\n  provider: \u001b[32m'bedrock'\u001b[39m,\r\n  modelName: \u001b[32m'arn:aws:bedrock:us-east-2:225681119357:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0'\u001b[39m,\r\n  message: \u001b[32m'Error in generating text'\u001b[39m,\r\n  err: \u001b[32m'ExpiredTokenException: The security token included in the request is expired'\u001b[39m\r\n}\r\n"]
[2.162544, "o", "\u001b[1G\u001b[?25h\u001b[31m‚úñ\u001b[39m bedrock: \u001b[31m‚ùå Failed\u001b[39m - Failed to generate text: The security token included in the request is expired\r\n"]
[2.162647, "o", "[AIProviderFactory.createProvider] Provider creation started { providerName: \u001b[32m'vertex'\u001b[39m, modelName: \u001b[32m'default'\u001b[39m }\r\n"]
[2.162718, "o", "[GoogleVertexAI.constructor] Initialization started { modelName: \u001b[32m'claude-sonnet-4@20250514'\u001b[39m, isAnthropic: \u001b[33mtrue\u001b[39m }\r\n[GoogleVertexAI.constructor] Authentication validation {\r\n  hasPrincipalAccountAuth: \u001b[33mfalse\u001b[39m,\r\n  projectId: \u001b[32m'dev-ai-beta'\u001b[39m,\r\n  location: \u001b[32m'us-east5'\u001b[39m\r\n}\r\n[GoogleVertexAI.constructor] Auth method missing { authMethod: \u001b[32m'none'\u001b[39m, hasPrincipalAccountAuth: \u001b[33mfalse\u001b[39m }\r\n"]
[2.162787, "o", "[GoogleVertexAI.constructor] Initialization completed {\r\n  modelName: \u001b[32m'claude-sonnet-4@20250514'\u001b[39m,\r\n  isAnthropic: \u001b[33mtrue\u001b[39m,\r\n  authMethod: \u001b[32m'none'\u001b[39m,\r\n  success: \u001b[33mtrue\u001b[39m\r\n}\r\n"]
[2.162809, "o", "[AIProviderFactory.createProvider] Provider creation succeeded {\r\n  providerName: \u001b[32m'vertex'\u001b[39m,\r\n  modelName: \u001b[32m'default'\u001b[39m,\r\n  providerType: \u001b[32m'GoogleVertexAI'\u001b[39m\r\n}\r\n"]
[2.162956, "o", "[GoogleVertexAI.generate] Generate request started {\r\n  provider: \u001b[32m'vertex'\u001b[39m,\r\n  modelName: \u001b[32m'claude-sonnet-4@20250514'\u001b[39m,\r\n  isAnthropic: \u001b[33mtrue\u001b[39m,\r\n  promptLength: \u001b[33m4\u001b[39m,\r\n  temperature: \u001b[33m0.7\u001b[39m,\r\n  maxTokens: \u001b[33m1\u001b[39m\r\n}\r\n"]
[2.163023, "o", "GoogleVertexAI.getModel - Anthropic model selected { modelName: \u001b[32m'claude-sonnet-4@20250514'\u001b[39m }\r\n"]
[2.167668, "o", "[GoogleVertexAI] Anthropic module successfully loaded\r\n"]
[2.16785, "o", "[setupGoogleAuth] Service account env auth (separate variables) {\r\n  hasClientEmail: \u001b[33mtrue\u001b[39m,\r\n  hasPrivateKey: \u001b[33mtrue\u001b[39m,\r\n  authMethod: \u001b[32m'service_account_env'\u001b[39m\r\n}\r\n"]
[2.168384, "o", "[setupGoogleAuth] Created temporary credentials file from env vars { tempFile: \u001b[32m'[CREATED]'\u001b[39m, authMethod: \u001b[32m'service_account_env_temp_file'\u001b[39m }\r\n"]
[2.168478, "o", "[createVertexSettings] Principal account auth (file path) { credentialsPath: \u001b[32m'[PROVIDED]'\u001b[39m, authMethod: \u001b[32m'principal_account_file'\u001b[39m }\r\n"]
[4.513195, "o", "[GoogleVertexAI.generate] Generate text completed {\r\n  provider: \u001b[32m'vertex'\u001b[39m,\r\n  modelName: \u001b[32m'claude-sonnet-4@20250514'\u001b[39m,\r\n  usage: { promptTokens: \u001b[33m15\u001b[39m, completionTokens: \u001b[33m1\u001b[39m, totalTokens: \u001b[33m16\u001b[39m },\r\n  finishReason: \u001b[32m'length'\u001b[39m,\r\n  responseLength: \u001b[33m5\u001b[39m\r\n}\r\n"]
[4.513331, "o", "\u001b[1G\u001b[?25h\u001b[32m‚úî\u001b[39m vertex: \u001b[32m‚úÖ Working\u001b[39m (2351ms)\r\n"]
[4.513381, "o", "[AIProviderFactory.createProvider] Provider creation started { providerName: \u001b[32m'anthropic'\u001b[39m, modelName: \u001b[32m'default'\u001b[39m }\r\n[AnthropicProvider] Initialized with model: claude-3-5-sonnet-20241022\r\n[AIProviderFactory.createProvider] Provider creation succeeded {\r\n  providerName: \u001b[32m'anthropic'\u001b[39m,\r\n  modelName: \u001b[32m'default'\u001b[39m,\r\n  providerType: \u001b[32m'AnthropicProvider'\u001b[39m\r\n}\r\n"]
[4.513655, "o", "[AnthropicProvider.generate] Starting text generation\r\n[AnthropicProvider.generate] Prompt: \"test...\", Temperature: 0.7, Max tokens: 1\r\n[AnthropicProvider.makeRequest] Non-streaming request to https://api.anthropic.com/v1/messages\r\n[AnthropicProvider.makeRequest] Model: claude-3-5-sonnet-20241022, Max tokens: 1\r\n"]
[6.498061, "o", "[AnthropicProvider.generate] Success. Generated 1 tokens\r\n\u001b[1G\u001b[?25h"]
[6.498218, "o", "\u001b[32m‚úî\u001b[39m anthropic: \u001b[32m‚úÖ Working\u001b[39m (1985ms)\r\n"]
[6.498286, "o", "[AIProviderFactory.createProvider] Provider creation started { providerName: \u001b[32m'azure'\u001b[39m, modelName: \u001b[32m'default'\u001b[39m }\r\n[AzureOpenAIProvider] Initialized with endpoint: https://ai-analyticshub339257712111.openai.azure.com, deployment: gpt-4o-mini\r\n[AIProviderFactory.createProvider] Provider creation succeeded {\r\n  providerName: \u001b[32m'azure'\u001b[39m,\r\n  modelName: \u001b[32m'default'\u001b[39m,\r\n  providerType: \u001b[32m'AzureOpenAIProvider'\u001b[39m\r\n}\r\n"]
[6.498401, "o", "[AzureOpenAIProvider.generate] Starting text generation\r\n[AzureOpenAIProvider.generate] Prompt: \"test...\", Temperature: 0.7, Max tokens: 1\r\n"]
[6.498468, "o", "[AzureOpenAIProvider.makeRequest] Non-streaming request to deployment: gpt-4o-mini\r\n[AzureOpenAIProvider.makeRequest] Max tokens: 1, Temperature: 0.7\r\n"]
[7.435968, "o", "[AzureOpenAIProvider.generate] Success. Generated 1 tokens\r\n"]
[7.43613, "o", "\u001b[1G\u001b[?25h\u001b[32m‚úî\u001b[39m azure: \u001b[32m‚úÖ Working\u001b[39m (938ms)\r\n"]
[7.436253, "o", "\u001b[1G\u001b[?25h\u001b[34m‚Ñπ\u001b[39m \u001b[34m\u001b[39m\r\n\u001b[34müìä Summary: 4/5 providers working\u001b[39m\r\n"]
[7.436383, "o", "\u001b[?25h"]
