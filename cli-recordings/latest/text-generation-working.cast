{"version": 2, "width": 195, "height": 42, "timestamp": 1749525740, "env": {"SHELL": "/bin/zsh", "TERM": "xterm-256color"}}
[0.366315, "o", "\u001b[?25l"]
[0.367042, "o", "\u001b[1G\u001b[1G\u001b[36m‚†ã\u001b[39m ü§ñ Generating text...[getBestProvider] Selected provider: openai\r\n"]
[0.367155, "o", "[AIProviderFactory.createBestProvider] Best provider selected {\r\n  requestedProvider: \u001b[32m'auto'\u001b[39m,\r\n  selectedProvider: \u001b[32m'openai'\u001b[39m,\r\n  modelName: \u001b[32m'default'\u001b[39m\r\n}\r\n[AIProviderFactory.createProvider] Provider creation started { providerName: \u001b[32m'openai'\u001b[39m, modelName: \u001b[32m'default'\u001b[39m }\r\n[OpenAI.constructor] Function called { modelName: \u001b[32m'gpt-4o'\u001b[39m }\r\n[OpenAI.constructor] Function result { modelName: \u001b[32m'gpt-4o'\u001b[39m, success: \u001b[33mtrue\u001b[39m }\r\n"]
[0.367316, "o", "[AIProviderFactory.createProvider] Provider creation succeeded {\r\n  providerName: \u001b[32m'openai'\u001b[39m,\r\n  modelName: \u001b[32m'default'\u001b[39m,\r\n  providerType: \u001b[32m'OpenAI'\u001b[39m\r\n}\r\n"]
[0.36741, "o", "[getBestProvider] Selected provider: openai\r\n"]
[0.369263, "o", "[OpenAI.generate] Generate text started {\r\n  provider: \u001b[32m'openai'\u001b[39m,\r\n  modelName: \u001b[32m'gpt-4o'\u001b[39m,\r\n  promptLength: \u001b[33m27\u001b[39m,\r\n  temperature: \u001b[33m0.7\u001b[39m,\r\n  maxTokens: \u001b[33m500\u001b[39m\r\n}\r\n"]
[0.447061, "o", "\u001b[1G"]
[0.447234, "o", "\u001b[0K\u001b[36m‚†ô\u001b[39m ü§ñ Generating text..."]
[0.527539, "o", "\u001b[1G\u001b[0K"]
[0.52769, "o", "\u001b[36m‚†π\u001b[39m ü§ñ Generating text..."]
[0.608751, "o", "\u001b[1G\u001b[0K\u001b[36m‚†∏\u001b[39m ü§ñ Generating text..."]
[0.688654, "o", "\u001b[1G\u001b[0K"]
[0.688795, "o", "\u001b[36m‚†º\u001b[39m ü§ñ Generating text..."]
[0.769293, "o", "\u001b[1G\u001b[0K"]
[0.769404, "o", "\u001b[36m‚†¥\u001b[39m ü§ñ Generating text..."]
[0.850261, "o", "\u001b[1G\u001b[0K"]
[0.850419, "o", "\u001b[36m‚†¶\u001b[39m ü§ñ Generating text..."]
[0.931456, "o", "\u001b[1G\u001b[0K"]
[0.931654, "o", "\u001b[36m‚†ß\u001b[39m ü§ñ Generating text..."]
[1.012796, "o", "\u001b[1G\u001b[0K\u001b[36m‚†á\u001b[39m ü§ñ Generating text..."]
[1.092318, "o", "\u001b[1G\u001b[0K"]
[1.092492, "o", "\u001b[36m‚†è\u001b[39m ü§ñ Generating text..."]
[1.172583, "o", "\u001b[1G\u001b[0K"]
[1.172691, "o", "\u001b[36m‚†ã\u001b[39m ü§ñ Generating text..."]
[1.253672, "o", "\u001b[1G\u001b[0K"]
[1.25379, "o", "\u001b[36m‚†ô\u001b[39m ü§ñ Generating text..."]
[1.334982, "o", "\u001b[1G\u001b[0K"]
[1.335091, "o", "\u001b[36m‚†π\u001b[39m ü§ñ Generating text..."]
[1.416228, "o", "\u001b[1G\u001b[0K\u001b[36m‚†∏\u001b[39m ü§ñ Generating text..."]
[1.497082, "o", "\u001b[1G\u001b[0K"]
[1.497114, "o", "\u001b[36m‚†º\u001b[39m ü§ñ Generating text..."]
[1.578227, "o", "\u001b[1G\u001b[0K"]
[1.578363, "o", "\u001b[36m‚†¥\u001b[39m ü§ñ Generating text..."]
[1.650883, "o", "[OpenAI.generate] Generate text completed {\r\n  provider: \u001b[32m'openai'\u001b[39m,\r\n  modelName: \u001b[32m'gpt-4o'\u001b[39m,\r\n  usage: { promptTokens: \u001b[33m23\u001b[39m, completionTokens: \u001b[33m17\u001b[39m, totalTokens: \u001b[33m40\u001b[39m },\r\n  finishReason: \u001b[32m'stop'\u001b[39m,\r\n  responseLength: \u001b[33m68\u001b[39m\r\n}\r\n"]
[1.651149, "o", "\u001b[1G\u001b[0K\u001b[?25h\u001b[32m‚úî\u001b[39m \u001b[32m‚úÖ Text generated successfully!\u001b[39m\r\n\r\nHello! I hope you're having a great day. How can I assist you today?\r\n\r\n"]
[1.651174, "o", "{\r\n  \"provider\": \"openai\",\r\n  \"usage\": {\r\n    \"promptTokens\": 23,\r\n    \"completionTokens\": 17,\r\n    \"totalTokens\": 40\r\n  },\r\n  \"responseTime\": 1284\r\n}\r\n\u001b[34m‚ÑπÔ∏è  40 tokens used\u001b[39m\r\n"]
[30.368324, "o", "\u001b[?25h"]
